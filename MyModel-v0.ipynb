{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyModel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "En8MczNik638",
        "MwmKo3gLrI-i"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsrqF1JoACYhY/JNEkeptD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lowbee2019/Algorithm/blob/master/MyModel-v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6keCkX-Hp7hg",
        "outputId": "9567ec80-62a7-442e-d8ac-2a895f9f9c69"
      },
      "source": [
        "!pip install tensorflow-federated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-federated\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/ed/fb2ea1b442efcd11303e5154efe397927910a02228952c8bdaa0835739bc/tensorflow_federated-0.18.0-py2.py3-none-any.whl (578kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.3.1)\n",
            "Collecting tensorflow-addons~=0.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 16.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax~=0.2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (0.2.11)\n",
            "Collecting tensorflow-privacy~=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ae/7db0dcf76a746314a174578a7b99ff098b40b908c4c693a955a2bbc0127b/tensorflow_privacy-0.5.1-py3-none-any.whl (149kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.3.3)\n",
            "Collecting attrs~=19.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
            "Collecting cachetools~=3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (0.12.0)\n",
            "Requirement already satisfied: tensorflow~=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (2.4.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (0.1.5)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.32.0)\n",
            "Requirement already satisfied: jaxlib~=0.1.55 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (0.1.64+cuda110)\n",
            "Collecting semantic-version~=2.8.5\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/15/00ef3b7888a10363b7c402350eda3acf395ff05bebae312d1296e528516a/semantic_version-2.8.5-py2.py3-none-any.whl\n",
            "Collecting tensorflow-model-optimization~=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.19.5)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (2.10.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons~=0.12.0->tensorflow-federated) (2.7.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.8->tensorflow-federated) (3.3.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated) (1.4.1)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated) (1.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated) (2.4.0)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from retrying~=1.3.3->tensorflow-federated) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (3.12.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (0.3.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->tensorflow-federated) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow~=2.4.0->tensorflow-federated) (54.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (1.28.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (0.4.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow~=2.4.0->tensorflow-federated) (3.1.0)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-addons, tensorflow-privacy, attrs, cachetools, semantic-version, tensorflow-model-optimization, tensorflow-federated\n",
            "  Found existing installation: attrs 20.3.0\n",
            "    Uninstalling attrs-20.3.0:\n",
            "      Successfully uninstalled attrs-20.3.0\n",
            "  Found existing installation: cachetools 4.2.1\n",
            "    Uninstalling cachetools-4.2.1:\n",
            "      Successfully uninstalled cachetools-4.2.1\n",
            "Successfully installed attrs-19.3.0 cachetools-3.1.1 semantic-version-2.8.5 tensorflow-addons-0.12.1 tensorflow-federated-0.18.0 tensorflow-model-optimization-0.5.0 tensorflow-privacy-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e4So1L3pPWp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import collections\n",
        "import tensorflow_federated as tff\n",
        "import copy\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQaIGTfxmSfi"
      },
      "source": [
        "# Server Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTK_p961nsA5"
      },
      "source": [
        "class ParamServer(object):\n",
        "  def __init__(self,init_model_path):\n",
        "    self.init_model_path = init_model_path\n",
        "    self.round = 0\n",
        "    self.optimizer=\"adam\"\n",
        "    self.loss = \"sparse_categorical_crossentropy\"\n",
        "    self.metrics =['accuracy']\n",
        "\n",
        "  def PreTrain(self,model,data,labels,batch_size=32,epochs=5):\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                  loss=self.loss,\n",
        "                  metrics=self.metrics)\n",
        "    model.fit(data,labels,batch_size,epochs)\n",
        "    return model\n",
        "  \n",
        "  def PreEval(self,model,test_data,test_labels):\n",
        "    model.compile(optimizer=self.optimizer,\n",
        "                  loss=self.loss,\n",
        "                  metrics=self.metrics)\n",
        "    model.evaluate(test_data,test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRvlGAmjmxbw"
      },
      "source": [
        "## Mnist数据集的预处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b0_4VEYnemW",
        "outputId": "9871920f-0ac0-40e5-ea03-0e9c81ec46e8"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "train,test = mnist.load_data()\n",
        "x_train,y_train = train\n",
        "x_test,y_test = test\n",
        "x_train,x_test = x_train/255.0,x_test/255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9537dMSO_C_",
        "outputId": "54fca4bc-0418-494c-fc95-f7f6664b30bf"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L712LCIm6Vv"
      },
      "source": [
        "## 模型的定义"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0noj5RjmF0i"
      },
      "source": [
        "class FLModel(tf.keras.Model):\n",
        "  def __init__(self,row,col,num_classes=62,*args,**kwargs):\n",
        "    super(FLModel,self).__init__(*args,**kwargs)\n",
        "    self.row = row\n",
        "    self.col = col\n",
        "    self.num_classes = num_classes\n",
        "    self.flatten = tf.keras.layers.Flatten(input_shape=(row,col))\n",
        "    self.dense_1 = tf.keras.layers.Dense(128,activation='relu',name=\"dense_1\")\n",
        "    self.dense_2 = tf.keras.layers.Dense(num_classes,activation='softmax',name=\"dense_2\")\n",
        "    self.drop = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.flatten(inputs)\n",
        "    x = self.dense_1(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.dense_2(x)\n",
        "    return x\n",
        "  \n",
        "  def copy(self):\n",
        "    NewModel = FLModel(self.row,self.col,self.num_classes)\n",
        "    _ = NewModel(np.expand_dims(tf.zeros([self.row,self.col]),0))\n",
        "    ##Layers\n",
        "    NewVars = NewModel.trainable_variables #此处为空列表，因为没有训练,这个地方参数传递是不是有问题\n",
        "    OldVars = self.trainable_variables\n",
        "    for n,o in zip(NewVars,OldVars):\n",
        "      n.assign(o.numpy())\n",
        "    # NewVars=OldVars[:]\n",
        "    return NewModel\n",
        "\n",
        "  # def compute_output_shape(self,input_shape):\n",
        "  #   shape = tf.TensorShape(input_shape).as_list()\n",
        "  #   shape[-1] = self.num_classes\n",
        "  #   return tf.TensorShape(shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_EOR39lCAk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5LMvoXcoiz2"
      },
      "source": [
        "#Client Initialization\n",
        "模型训练和评估都要重写"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvu8wCjbooCF"
      },
      "source": [
        "class Client(object):\n",
        "  def __init__(self,id,model=None,Train_dataset=None,Test_dataset=None):\n",
        "    self.id = id\n",
        "    self.model = model\n",
        "    self.Train_dataset = Train_dataset\n",
        "    self.Test_dataset = Test_dataset\n",
        "    # from ParamServer\n",
        "    self.ParamModel = None\n",
        "    self.num_epochs = 5\n",
        "    self.batch_size = 32\n",
        "    self.shuffle_buffer = 100\n",
        "    self.prefetch_buffer = 10\n",
        "\n",
        "\n",
        "  def ReceiveModel(self,ParamModel,num_epochs=1,batch_size=32,shuffle_buffer=100,prefetch_buffer=10):\n",
        "    self.ParamModel = ParamModel\n",
        "    self.num_epochs = num_epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle_buffer = shuffle_buffer\n",
        "    self.prefetch_buffer = prefetch_buffer\n",
        "\n",
        "  def preprocess(self,dataset):\n",
        "    def batch_format_fn(element):\n",
        "      return collections.OrderedDict(\n",
        "            \n",
        "            x = tf.reshape(element['pixels'],[-1,784]),\n",
        "            y = tf.reshape(element['label'],[-1,1])\n",
        "          )\n",
        "    return dataset.repeat(self.num_epochs).shuffle(self.shuffle_buffer).batch(\n",
        "        self.batch_size).map(batch_format_fn).prefetch(self.prefetch_buffer)\n",
        "\n",
        "  def NodeTrain(self):\n",
        "    model = self.ParamModel\n",
        "    # pre_data = self.preprocess(self.Train_dataset)\n",
        "    # print(type(pre_data))\n",
        "    # model.fit(x=pre_data['x'],y=pre_data['y'],batch_size=self.batch_size,epochs=self.num_epochs)\n",
        "    # x = np.array([i['pixels'].numpy() for i in self.Train_dataset])\n",
        "    # y = np.array([i['label'].numpy() for i in self.Train_dataset])\n",
        "    x,y = self.Train_dataset\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    model.fit(x,y,batch_size=self.batch_size,epochs=self.num_epochs)\n",
        "    self.model = model\n",
        "\n",
        "  def NodeEval(self):\n",
        "    # x = np.array([i['pixels'].numpy() for i in self.Test_dataset])\n",
        "    # y = np.array([i['label'].numpy() for i in self.Test_dataset])\n",
        "    x,y = self.Test_dataset\n",
        "    self.model.evaluate(x,y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En8MczNik638"
      },
      "source": [
        "#阶段一：服务器完成模型初始化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M8BnvO4cozYf"
      },
      "source": [
        "InitModel = FLModel(row=28,col=28,num_classes=62)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY59Q1O0tkpl",
        "outputId": "cfb4c983-625a-4f93-d50f-3bf3267e0eb6"
      },
      "source": [
        "S.PreEval(InitModel,x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow52yxhUzpJh",
        "outputId": "75326073-1003-4f56-c057-62405ba346c9"
      },
      "source": [
        "S = ParamServer('')\n",
        "SendModel = S.PreTrain(InitModel,x_train,y_train,epochs=1)\n",
        "S.PreEval(SendModel,x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1685 - accuracy: 0.9511\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvf7A9YrEnA6",
        "outputId": "c08a830b-bdcf-4508-b2fe-b30330c2d2c1"
      },
      "source": [
        "#x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwmKo3gLrI-i"
      },
      "source": [
        "# 阶段二：为Client分配数据（预处理工作）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjztXWZ1N_Z7",
        "outputId": "dd08a82f-c817-4296-9bd1-7cc1a93fe4c4"
      },
      "source": [
        "# emnist_train,emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_emnist.tar.bz2\n",
            "169811968/169808360 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho09LMxTeEy1",
        "outputId": "88352a06-8fe4-4cbd-a467-7db43b0a3b0b"
      },
      "source": [
        "!pip install emnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emnist\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f4/78b24acbef9e8fe976dda700f16a3606f3b8363b015bc555f8050fbbd8ac/emnist-0.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from emnist) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from emnist) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from emnist) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2020.12.5)\n",
            "Installing collected packages: emnist\n",
            "Successfully installed emnist-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezNQYfeEjj_S"
      },
      "source": [
        "import emnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcXnArpEjnnA"
      },
      "source": [
        "emnist_dataset = emnist.extract_training_samples('byclass')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzqa4xQCsTHk"
      },
      "source": [
        "#len(emnist_train.client_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB5EFASJsiUm"
      },
      "source": [
        "#emnist_train.element_type_structure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kilZeXxMszHg"
      },
      "source": [
        "#example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txgAL1lTtX01"
      },
      "source": [
        "#example_element = next(iter(example_dataset))\n",
        "#example_element['label'].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlR96ORjbt5V"
      },
      "source": [
        "def create_data_for_clients(BasicSet,Num):\n",
        "  x_sequence = []\n",
        "  y_sequence = []\n",
        "  for i in range(Num):\n",
        "    index = random.randint(0,Num-1)\n",
        "    x_sequence.append(BasicSet[0][index])\n",
        "    y_sequence.append(BasicSet[1][index])\n",
        "  return (np.array(x_sequence),np.array(y_sequence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE_WXcMMt1kP"
      },
      "source": [
        "NUM_CLIENTS = 10\n",
        "NUM_TRAIN_SAMPLE_CLIENT = 640\n",
        "NUM_TEST_SAMPLE_CLIENT = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nNTgVhYMX-h"
      },
      "source": [
        "# clients=[Client(i,Train_dataset=train,Test_dataset=test) for i in range(NUM_CLIENTS)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcx_z2Jbsqo"
      },
      "source": [
        "clients=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tmf__umcO1l"
      },
      "source": [
        "for i in range(NUM_CLIENTS):\n",
        "  clients.append(Client(i,\n",
        "                        Train_dataset=create_data_for_clients(emnist_dataset,NUM_TRAIN_SAMPLE_CLIENT),\n",
        "                        Test_dataset=create_data_for_clients(emnist_dataset,NUM_TEST_SAMPLE_CLIENT))\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISM6787PtqAJ"
      },
      "source": [
        "# clients = [Client(i,Train_dataset=emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[i]),\n",
        "#                     Test_dataset=emnist_test.create_tf_dataset_for_client(emnist_test.client_ids[i])\n",
        "#                     )\n",
        "#                  for i in range(NUM_CLIENTS) ] #此处需要重写，用于确定数字占比"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM7N4idLwVfz"
      },
      "source": [
        "#clients[0].Train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psa6qznDOggE"
      },
      "source": [
        "#len(clients[0].Train_dataset),len(clients[0].Test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OmptaMzpR0P"
      },
      "source": [
        "# 阶段三：Clients 训练节点数据并聚合\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wefk859SVCz"
      },
      "source": [
        "## 节点训练\n",
        "OK！fine,我这两天就是为了实现一个循环。。。\n",
        "真他娘的丢人"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "BqZPIlu6QQjN",
        "outputId": "9bb8e827-55cd-4685-a9f6-b9a08401d64b"
      },
      "source": [
        "for i in range(NUM_CLIENTS):\n",
        "  clients[i].ReceiveModel(a.copy())\n",
        "  clients[i].NodeTrain()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-fe3d876bb572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLIENTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReceiveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNodeTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoYtJOhkROaV",
        "outputId": "f22e3092-0849-4303-e944-f590c62aa997"
      },
      "source": [
        "for i in range(NUM_CLIENTS):\n",
        "  print(\"Node {} is evaluating...\".format(i))\n",
        "  clients[i].NodeEval()\n",
        "  ##虽然这个步骤没啥用"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node 0 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.9269\n",
            "Node 1 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.9273\n",
            "Node 2 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.9271\n",
            "Node 3 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.9242\n",
            "Node 4 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.9231\n",
            "Node 5 is evaluating...\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3814 - accuracy: 0.9300\n",
            "Node 6 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.9262\n",
            "Node 7 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.9250\n",
            "Node 8 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.9242\n",
            "Node 9 is evaluating...\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.9185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXF-zOUIZGDO"
      },
      "source": [
        "def DiffModel(model1,model2,layer_name,w_vs_b=0):\n",
        "  l1 = model1.get_layer(layer_name).get_weights()[w_vs_b].reshape([-1,])\n",
        "  l2 = model2.get_layer(layer_name).get_weights()[w_vs_b].reshape([-1,])\n",
        "  # l1 = model1.trainable_variables\n",
        "  # l2 = model2.trainable_variables\n",
        "  # print(l1)\n",
        "  l1.shape\n",
        "  # l1 = l1.reshape([-1,])\n",
        "  # l2 = l2.reshape([-1,])\n",
        "  for i in range(len(l1)):\n",
        "    if l1[i]!=l2[i]:\n",
        "      print(\"NOT SAME MODEL\")\n",
        "      return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYehgejDZJZw",
        "outputId": "f8c651dd-b7b4-41a7-f3ca-67afd9d626cd"
      },
      "source": [
        "DiffModel(clients[0].model,clients[1].model,'dense_1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOT SAME MODEL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpREw9q5Se9f"
      },
      "source": [
        "## 模型聚合 FedAvg\n",
        "THIS IS THE MOST IMPORANT！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RRqKgiqSRFF"
      },
      "source": [
        "##先实现普通聚合，再考虑距离问题"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIOKI885TN31",
        "outputId": "75a8957a-2d67-49f9-d0a1-d340a623ce3f"
      },
      "source": [
        "# clients[0].Train_dataset[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9fgFEGKT41m",
        "outputId": "e4c6fb02-b699-4c76-a013-0163740fe1e8"
      },
      "source": [
        "# a_1 = a.trainable_variables\n",
        "# b_1 = clients[0].model.trainable_variables\n",
        "# for _a,_b in zip(a_1,b_1):\n",
        "#   # print(_a,_b,'\\n')\n",
        "#   print(type(_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.eager.def_function.UnliftedInitializerVariable'>\n",
            "<class 'tensorflow.python.eager.def_function.UnliftedInitializerVariable'>\n",
            "<class 'tensorflow.python.eager.def_function.UnliftedInitializerVariable'>\n",
            "<class 'tensorflow.python.eager.def_function.UnliftedInitializerVariable'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJUbvaVsZP4P"
      },
      "source": [
        "# tmp = a_1[0]\n",
        "# tmp2 = b_1[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYDG5UaqZP1s",
        "outputId": "f27ff669-b776-488d-f1a6-85d06edbf27e"
      },
      "source": [
        "# print(tmp.name)\n",
        "# print(tmp2.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fl_model_57/dense_1/kernel:0\n",
            "fl_model_60/dense_1/kernel:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MCj2AqXZPzY",
        "outputId": "0102b751-5f6c-4f17-d7fb-361d68ba5c3c"
      },
      "source": [
        "# tmp.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07970653,  0.07991762,  0.05910995, ...,  0.0579403 ,\n",
              "         0.0321511 ,  0.02421231],\n",
              "       [-0.05695383,  0.03625515, -0.06860252, ...,  0.02591816,\n",
              "         0.04554088,  0.02055327],\n",
              "       [-0.01783558, -0.04462572, -0.02057564, ...,  0.02187481,\n",
              "        -0.04054561, -0.02853347],\n",
              "       ...,\n",
              "       [-0.05783828, -0.05880497,  0.07976013, ..., -0.03510847,\n",
              "        -0.03695404,  0.03616227],\n",
              "       [-0.06651882,  0.02818294, -0.02726433, ..., -0.05769905,\n",
              "        -0.04426115, -0.00901749],\n",
              "       [-0.01624558,  0.05673347, -0.07569796, ..., -0.05263541,\n",
              "        -0.0753431 , -0.04903179]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kMMoHjAg6ZA",
        "outputId": "7530bd17-18dd-4904-93c1-a465a682b56e"
      },
      "source": [
        "# tmp.numpy().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szwdWjJOhhPO"
      },
      "source": [
        "#  tmp2 =np.zeros(a.trainable_variables[0].numpy().shape,dtype='float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThtNgQgrhncc",
        "outputId": "cc972f15-4527-4670-a94a-98797e7e253f"
      },
      "source": [
        "# tmp2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YopyPHTFZPw0"
      },
      "source": [
        "#聚合先不考虑权重\n",
        "def FedAvg(NUM_CLIENTS):\n",
        "  iterModel = a.copy()\n",
        "  len_it = len(iterModel.trainable_variables)\n",
        "  all_weights = []\n",
        "  for weights_index in range(len_it):\n",
        "    tmp =np.zeros(iterModel.trainable_variables[weights_index].numpy().shape,dtype='float64')\n",
        "\n",
        "    for node in range(NUM_CLIENTS):\n",
        "      tmp += clients[node].model.trainable_variables[weights_index].numpy()\n",
        "    all_weights.append(tmp)\n",
        "  # print(all_weights)\n",
        "  iterModel_vars = iterModel.trainable_variables\n",
        "  for iter_v,n in zip(iterModel_vars,all_weights):\n",
        "    iter_v.assign(n)\n",
        "  return iterModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlyPcfg2ZPuM"
      },
      "source": [
        "fedmodel = FedAvg(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4fq1H9TZPq2"
      },
      "source": [
        "#昨天留的任务是如何把聚合后的numpy数组，转到模型中"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EWPH4k7RSYB",
        "outputId": "bbcaabfd-3c96-4aa0-9829-78d0eb485287"
      },
      "source": [
        "S.PreEval(fedmodel,x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 7.8235 - accuracy: 0.2031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_8dKE06KK4e",
        "outputId": "67908246-b8a4-4577-bd63-5c230caa5209"
      },
      "source": [
        "len(fed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZjJI4ukUahO"
      },
      "source": [
        "## 基本框架已经"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbSCRmESJF9t"
      },
      "source": [
        "iter2 = a.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho1UhyNaZPfW"
      },
      "source": [
        "iter2_vars = iter2.trainable_variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f_0uYHgZPXo"
      },
      "source": [
        "iter2_vars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWtESvetJjNa"
      },
      "source": [
        "for _v1,_v2 in zip(iter2_vars,fed):\n",
        "  _v1.assign(_v2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7byxEhHK1ax",
        "outputId": "5c160ef6-a51a-4838-fad8-96dfef2b8462"
      },
      "source": [
        "DiffModel(iter2,a,'dense_1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOT SAME MODEL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi3EkWQbKaoW"
      },
      "source": [
        "b = clients[0].model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIlSsgN6KeIO"
      },
      "source": [
        "v1 = a.trainable_variables\n",
        "v2 = b.trainable_variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap0w-jMzmE73",
        "outputId": "66293f93-e729-4d7e-816d-7d16d9b4db64"
      },
      "source": [
        "b = FLModel(28,28,62)\n",
        "v1 = a.trainable_variables\n",
        "# S.PreTrain(b,x_train,y_train)\n",
        "v2 = b.trainable_variables\n",
        "print(b.trainable_variables)\n",
        "# for v_1,v_2 in zip(v1,v2):\n",
        "#   print(\"??\")\n",
        "  # v_1.assign(v_2.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-rRVGNT1Jht"
      },
      "source": [
        "v2=v1[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwsh_-Xx1fnX",
        "outputId": "ab2470a9-3636-400d-d78a-d9469c973d0e"
      },
      "source": [
        "id(v2),id(b.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140499046190288, 140499104477984)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV6urI8DvMNL",
        "outputId": "83db9444-9222-42cd-dfc2-ffa7c0cd0d15"
      },
      "source": [
        "id(a.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140499217825136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb2keHfgtyar"
      },
      "source": [
        "tmpmodel = keras.models.Sequential([\n",
        "                                   keras.layers.Dense(32,input_shape=(784,),activation='relu'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8SdRmXUtyYl",
        "outputId": "e18d2280-e675-4d52-8c9c-fe92fdccede0"
      },
      "source": [
        "tmpmodel.trainable_variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_1/kernel:0' shape=(784, 32) dtype=float32, numpy=\n",
              " array([[ 0.07944056, -0.01687008,  0.06158806, ...,  0.02253681,\n",
              "         -0.00866669,  0.05025689],\n",
              "        [-0.07876401,  0.06727929, -0.04862248, ..., -0.0574102 ,\n",
              "          0.0471491 ,  0.00323779],\n",
              "        [ 0.02786615,  0.0126921 , -0.03494832, ...,  0.04175083,\n",
              "         -0.0363945 ,  0.05179618],\n",
              "        ...,\n",
              "        [ 0.06009207, -0.02396834, -0.06391142, ...,  0.04591579,\n",
              "          0.00446624,  0.06287944],\n",
              "        [ 0.03360625,  0.03261185,  0.08488534, ...,  0.04576839,\n",
              "          0.02080478, -0.05224812],\n",
              "        [-0.06869756,  0.05392497, -0.01011685, ...,  0.04216174,\n",
              "         -0.04211827,  0.07964728]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3KMNcCltyVb"
      },
      "source": [
        "z = FLModel(28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEI4LkCeF1-_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}